---
id: 4
title: "《逃离鸭科夫》yolo图像识别实战"
date: "2025-12"
image: "/homepage/images/duckov_1.jpg"
tags: ["pytorch","CUDA","yolo","python"]
desc: "使用自己的训练集调整训练的yolo模型以及自动瞄准"
---

## 1. 项目背景与概述
本项目旨在探索深度学习模型在极低延迟、高精度实时交互场景下的工程化应用。系统通过实时捕获高分辨率屏幕图像，利用轻量化卷积神经网络进行特征提取，并将推理结果实时转化为物理级鼠标位移指令，实现对特定目标的自动化识别与精准跟踪。
<img src="/homepage/images/duckov_2.jpg"  width=50%> 

## 2. 系统架构设计

### 2.1 数据工程与预处理
* **动态中心切片算法 (Dynamic Crop)**：针对 2K 分辨率（2560×1600）环境下目标特征占比过小的问题，设计了以鼠标为中心的 $640 \times 640$ 动态视窗。该方案避免了全屏缩放造成的像素丢失，显著提升了模型对远距离小目标的检测精度（mAP）。
* **样本多样性优化**：构建了包含 `Enemy`（身体）、`Head`（头部）及 `Self`（自身）的多分类数据集。通过引入大量的背景负样本（Negative Samples），有效抑制了复杂地形环境下的误报率（False Positives）。

### 2.2 核心模型实现
* **架构选型**：基于 **YOLO11s** 架构进行迁移学习。利用 C3k2 模块的特征提取能力，在保证推理速度的前提下，提升了对遮挡目标的识别稳健性。
* **超参数调优**：基于 **F1-Confidence Curve** 选定最优置信度阈值（0.626），在精确率（Precision）与召回率（Recall）之间取得了最佳平衡。



### 2.3 硬件级交互逻辑
* **低延迟截帧**：采用 **DXCam** 调用 Windows 桌面重复复制 API（Desktop Duplication API），实现 144Hz 以上的采样率。
* **控制算法逻辑**：
    * **多级优先级**：系统优先锁定头部中心，无头目标时自动回退至身体区域。
    * **坐标补偿**：通过欧几里得距离算法筛选距准星最近的目标，并应用平滑因子（Aim Speed）减少物理移动的机械感。
    * **死区管理**：引入强制步进补偿逻辑，消除了浮点数坐标取整带来的末端定位误差。



## 3. 性能表现 (RTX 4060 Laptop)

| 指标项目 | 测量数值 | 技术说明 |
| :--- | :--- | :--- |
| **单帧推理延迟** | 1.8ms | 模型前向传播耗时 |
| **系统综合响应时间** | < 8ms | 从截帧、推理到控制执行的总延迟 |
| **mAP50-95** | 0.89 | 高重合度下的平均精度均值 |
| **目标分类数** | 3 Classes | 支持敌人、头部及自身过滤 |

## 4. 技术反思与总结
实验结果证明，AI 辅助系统性能的上限取决于数据集的分布质量，而下限则取决于控制算法的平稳性。本项目通过**局部切片推理**与**强制步进补偿**，成功解决了深度学习模型在实际部署中常见的“目标过小”与“末端抖动”两大痛点。

---

**项目演示视频**：<a href="https://www.bilibili.com/video/BV1Woi5BMEXS/" target="_blank">https://www.bilibili.com/video/BV1Woi5BMEXS/</a>
**源代码仓库**：<a href="https://github.com/phenol-cat/duckov-auto-aim" target="_blank">https://github.com/phenol-cat/duckov-auto-aim</a>
